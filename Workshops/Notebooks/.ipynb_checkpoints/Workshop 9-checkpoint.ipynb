{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMP90051 Workshop 9\n",
    "## Bayesian Regression\n",
    "***\n",
    "\n",
    "In this worksheet, we'll revisit linear regression from a Bayesian perspective. \n",
    "We'll build on the standard frequentist approach to linear regression (see Worksheet 3), which assumes a conditional model for the response of the form: \n",
    "\n",
    "$$\n",
    "y_i | \\mathbf{x}_i \\sim \\operatorname{Normal}[\\mathbf{x}_i^\\top \\mathbf{w}, \\sigma^2], \\quad \\forall i \\in \\{1, \\ldots, n\\}\n",
    "$$\n",
    "\n",
    "where $\\mathbf{x}_i \\in \\mathbb{R}^{d}$ is a vector of predictors (prepended with a constant predictor to incorporate a bias term), $\\mathbf{w} \\in \\mathbb{R}^{d}$ is an unknown weight vector and $\\sigma^2$ is a known constant variance.\n",
    "\n",
    "Working from a Bayesian perspective, we'll treat the unknown weight vector $\\mathbf{w}$ as a _random variable_ and specify a prior distribution that encodes our belief about $\\mathbf{w}$ before observing any data.\n",
    "We'll then apply Bayesian inference to update our belief about $\\mathbf{w}$ after observing data, and to make predictions using _all settings of the weights_ according to their posterior probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.dpi'] = 108\n",
    "np.random.seed(1)\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.linear_model import BayesianRidge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Regression data set\n",
    "Let's generate a small synthetic data set in 1D according to the following model:\n",
    "\n",
    "$$\n",
    "\\newcommand\\ys{\\mathbf{y}}\n",
    "\\newcommand\\xs{\\mathbf{x}}\n",
    "\\newcommand\\Xs{\\mathbf{X}}\n",
    "\\newcommand\\ws{\\mathbf{w}}\n",
    "\\newcommand\\Vs{\\mathbf{V}}\n",
    "\\newcommand\\Is{\\mathbf{I}}\n",
    "\\begin{align*}\n",
    "x_i &\\sim \\mathrm{Uniform}[0,1] \\\\\n",
    "y_i | x_i, \\sigma^2 &\\sim \\mathrm{Normal}\\!\\left[5\\left(x - \\frac{1}{2}\\right)^2, \\sigma^2 \\right]\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "By focussing on the 1D case, it'll be straightforward to visualise the results.\n",
    "We'll keep the data set small, since Bayesian approaches are particularly useful when limited data is available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_instances = 8\n",
    "sigma = 0.1 # keep this small: don't want too much noise\n",
    "\n",
    "# generate data matrix with rows as instances\n",
    "X = np.random.uniform(size=(n_instances,1))\n",
    "\n",
    "# generate the target response values using the quadratic function\n",
    "# and additive noise\n",
    "Y = np.random.normal(loc=5*(X - 0.5)**2, scale=sigma, size=(n_instances,1)).ravel()\n",
    "\n",
    "# plot the training data\n",
    "plt.plot(X, Y, 'ro', label='Train')\n",
    "\n",
    "# and plot the true function (without noise)\n",
    "X_test = np.linspace(-0.2, 1.2, 100)\n",
    "X_test = X_test[:,np.newaxis]\n",
    "Y_test_gold = 5*(X_test - 0.5)**2 \n",
    "plt.plot(X_test, Y_test_gold, 'k', label='Model mean')\n",
    "plt.legend()\n",
    "plt.xlabel('$x$')\n",
    "plt.ylabel('$y$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Polynomial basis functions\n",
    "Since the relationship between $y$ and $x$ is non-linear, we'll apply polynomial basis expansion to degree $k$.\n",
    "Specifically, we replace the original data matrix $\\mathbf{X}$ by the transformed matrix\n",
    "\n",
    "$$\n",
    "\\mathbf{\\Phi} = \\begin{bmatrix}\n",
    "    1 & x_1 & x_1^2 & \\ldots & x_1^k \\\\\n",
    "    1 & x_2 & x_2^2 & \\ldots & x_2^k \\\\\n",
    "    \\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "    1 & x_n & x_n^2 & \\ldots & x_n^k \\\\\n",
    "\\end{bmatrix}.\n",
    "$$\n",
    "\n",
    "Note that we're including a column of ones to incorporate a bias term.\n",
    "\n",
    "The function below is a wrapper around `sklearn.preprocessing.PolynomialFeatures`, which implements the above transformation on a train/test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def polynomial_features(X_train, X_test, degree, include_bias=True):\n",
    "    \"\"\"\n",
    "    Augments data matrices X_train and X_test with polynomial features\n",
    "    \"\"\"\n",
    "    poly = PolynomialFeatures(degree=degree, include_bias=include_bias)\n",
    "    \n",
    "    Phi_train = poly.fit_transform(X_train)\n",
    "    Phi_test = poly.fit_transform(X_test)\n",
    "    \n",
    "    return Phi_train, Phi_test\n",
    "    \n",
    "Phi, Phi_test = polynomial_features(X, X_test, 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "**Discussion question**: How does this basis trick relate to kernel methods?\n",
    "***\n",
    "\n",
    "### 2. Bayesian regression with known variance\n",
    "\n",
    "Let's begin with a quick recap of the model introduced in lectures. \n",
    "As mentioned in the intro, the likelihood is identical to the one used in standard frequentist linear regression.\n",
    "What's new is the prior on the weight vector $\\ws$, which is assumed to be normal with mean zero and isotropic variance $\\gamma^2$:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\ws | \\gamma &\\sim \\operatorname{Normal}\\!\\left[\\mathbf{0}, \\gamma^2 \\mathbf{I}_{d}\\right] \\\\\n",
    "y_i | \\xs_i, \\ws, \\sigma &\\sim \\operatorname{Normal}\\!\\left[\\xs_i^\\top \\ws, \\sigma^2\\right] & \\forall i \\in \\{1,\\ldots,n\\}\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "By setting the prior mean to zero and choosing a small $\\gamma^2$, we are effectively penalising weight vectors with a large $L_2$ norm.\n",
    "\n",
    "Given this model, the next step is to solve for the posterior over $\\ws$\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "p(\\ws | \\Xs, \\ys, \\sigma, \\gamma) \n",
    "= \\frac{p(\\ys | \\Xs, \\ws, \\sigma) p(\\ws | \\gamma)}{p(\\ys | \\Xs, \\sigma)} \n",
    "= \\frac{\\prod_{i=1}^n p(y_i | \\xs_i, \\ws, \\sigma) p(\\ws | \\gamma)}{\\int_{\\ws} d\\ws\\prod_{i=1}^n p(y_i | \\xs_i, \\ws, \\sigma) p(\\ws | \\gamma)} \n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "where $\\Xs \\in \\mathbb{R}^{n \\times d}$ is a matrix of observed predictors and $\\ys \\in \\mathbb{R}^{n}$ is the corresponding vector of observed responses.\n",
    "\n",
    "In lectures, we derived the following solution:\n",
    "\n",
    "$$\n",
    "\\ws | \\Xs, \\ys, \\sigma, \\gamma \\sim \\operatorname{Normal}[\\ws_N, \\mathbf{V}_N]\n",
    "$$\n",
    "\n",
    "where $\\Vs_N = \\sigma^2 \\left( \\Xs^\\top \\Xs + \\frac{\\sigma^2}{\\gamma^2} \\Is_{d} \\right)^{-1}$ and $\\ws_N = \\frac{1}{\\sigma^2} \\Vs_N \\Xs^\\top \\ys$.\n",
    "\n",
    "***\n",
    "**Exercise:** Complete the function below to compute the posterior mean $\\ws_N$ and covariance matrix $\\Vs_N$ for the weights based on the expression above.\n",
    "\n",
    "_Hints:_\n",
    "* _the NumPy `@` operator represents matrix multiplication_\n",
    "* _`np.linalg.inv` can be used to compute the matrix inverse_\n",
    "* _`np.identity` or `np.eye` can be used to generate an identity matrix_\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_posterior_params(X, Y, sigma, gamma):\n",
    "    \"\"\"\n",
    "    Compute the parameters (mean and covariance) for the posterior over the weights\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X : numpy array, shape (n_instances, n_features)\n",
    "        feature matrix\n",
    "    Y : numpy array, shape (n_instances,)\n",
    "        target class labels relative to X\n",
    "    sigma : float\n",
    "        positive scale parameter for y\n",
    "    gamma : float\n",
    "        positive scale parameter for w_i\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    The following items in a tuple:\n",
    "    w_N : numpy array, shape (n_features,)\n",
    "        mean parameter\n",
    "    V_N : numpy array, shape (n_features, n_features)\n",
    "        covariance parameter\n",
    "    \"\"\"\n",
    "    V_N = ... # fill in\n",
    "    w_N = ... # fill in\n",
    "    \n",
    "    return w_N, V_N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = 10 # larger implies more permissive, i.e. a more diffuse prior\n",
    "w_N, V_N = compute_posterior_params(Phi, Y, sigma, gamma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the prior and posterior over $\\mathbf{w}$ to see how they differ. \n",
    "Since $\\mathbf{w}$ is $d$-dimensional, we can only visualise the posterior over a couple of components at a time.\n",
    "Here we look at $p(w_1, w_2|\\mathbf{X}, \\mathbf{y}, \\sigma, \\gamma)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up a 2d plot mesh\n",
    "w1, w2 = np.mgrid[-10:10:.05, -10:10:.05]\n",
    "grid = np.c_[w1.ravel(), w2.ravel()]\n",
    "\n",
    "# which weights do we want to see?\n",
    "i = 1\n",
    "j = 2\n",
    "\n",
    "fig = plt.figure(figsize=(10,5))\n",
    "# plot a bivariate normal for the prior\n",
    "ax = fig.add_subplot(121)\n",
    "p_w = sp.stats.multivariate_normal.pdf(grid, mean=np.zeros(2), cov=gamma**2 * np.identity(2))\n",
    "CS = ax.contour(w1, w2, p_w.reshape(w1.shape))\n",
    "plt.clabel(CS, inline=1, fontsize=10)\n",
    "ax.plot(0, 0, 'rx') # add prior mean\n",
    "plt.xlabel('$w_1$')\n",
    "plt.ylabel('$w_2$')\n",
    "plt.title('Prior $p(w_1, w_2|\\gamma)$')\n",
    "\n",
    "# plot a bivariate normal for the posterior\n",
    "ax = fig.add_subplot(122)\n",
    "mean = np.array([w_N[i],w_N[j]])\n",
    "cov = np.vstack([[V_N[i,i], V_N[i,j]], [V_N[j,i], V_N[j,j]]])\n",
    "p_w = sp.stats.multivariate_normal.pdf(grid, mean=mean, cov=cov)\n",
    "CS = ax.contour(w1, w2, p_w.reshape(w1.shape))\n",
    "plt.clabel(CS, inline=1, fontsize=10)\n",
    "ax.plot(w_N[i], w_N[j], 'rx') # add posterior mean\n",
    "plt.xlabel('$w_1$')\n",
    "plt.ylabel('$w_2$')\n",
    "plt.title('Posterior $p(w_1, w_2|X,y,\\gamma,\\sigma)$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "**Discussion question**: Can you explain why the prior and the posterior are so different? How is this related to the dataset? *You may like to change the parameter indices from 1,2 to other pairs to get a better idea of the full posterior.*\n",
    "***\n",
    "\n",
    "### 3. Making predictions\n",
    "\n",
    "We've seen how to compute the posterior of the unknown weight vector $\\ws$. \n",
    "But how can we use the posterior to make a prediction for a new test instance $\\xs_*$?\n",
    "The proper Bayesian approach is to average over the predictions of all possible models, weighted by their posterior probability:\n",
    "\n",
    "$$\n",
    "\\underbrace{p(y_* | \\xs_*, \\Xs, \\ys, \\sigma^2, \\gamma^2)}_{\\text{posterior predictive}} = \\int \\underbrace{p(y_*|\\xs_*, \\ws, \\sigma^2)}_{\\text{likelihood}} \\underbrace{p(\\ws| \\Xs, \\ys, \\gamma^2)}_{\\text{posterior}} \\, \\mathrm{d} \\ws\n",
    "$$\n",
    "\n",
    "When we do this, we get a new distribution over the response called the _posterior predictive_ which incorporates the uncertainty in $\\ws$.\n",
    "Unfortunately, it's not always possible to obtain an expression for the posterior predictive distribution in closed form. \n",
    "In these circumstances, we can obtain an approximation based on sampling:\n",
    "\n",
    "$$\\hat{p}(y_* | \\xs_*, \\Xs, \\ys, \\sigma^2, \\gamma^2) = \\frac{1}{S} \\sum_{s = 1}^{S} \\mathbb{1}[y_* = y_s]$$ \n",
    "\n",
    "where each sample $y_s$ is obtained as follows:\n",
    "\n",
    "1. $\\ws_s$ is drawn from the posterior: $p(\\ws | \\Xs, \\ys, \\gamma^2) = \\operatorname{Normal}[\\ws; \\ws_N, \\mathbf{V}_N]$\n",
    "1. $y_s$ is drawn from the likelihood conditioned on $\\ws = \\ws_s$: $p(y_s | \\xs_*, \\ws_s, \\sigma^2) = \\operatorname{Normal}[y_s; \\xs_*^\\top \\ws_s, \\sigma^2]$\n",
    "\n",
    "***\n",
    "**Exercise:** Complete the inner loop in the code block below to draw a sample from the posterior predictive distribution for all instances in the test set.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate samples from the posterior predictive\n",
    "n_samples = 100\n",
    "for s in range(n_samples):\n",
    "    # Draw weight vector from the posterior\n",
    "    w_s = ... # fill in\n",
    "    # Compute predictive mean for all test instances simultaneously given \n",
    "    # w = w_s\n",
    "    mu = Phi_test @ w_s\n",
    "    # Draw responses for all test instances simultaneously given w = w_s\n",
    "    y_s = ... # fill in\n",
    "    \n",
    "    # Plot the responses for all test instances\n",
    "    p = plt.plot(X_test.ravel(), y_s, ':', lw=1)\n",
    "\n",
    "plt.plot(X, Y, 'ro', label='Train')\n",
    "plt.plot(X_test, Phi_test @ w_N, 'g:', label='Sample')\n",
    "plt.plot(X_test.ravel(), Y_test_gold, 'k', label='Model mean')\n",
    "\n",
    "plt.ylim(-2, 5)\n",
    "plt.xlabel('$x$')\n",
    "plt.ylabel('$y$')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's interesting to see what happens near the data points in the training set, and away from them.\n",
    "We'll come back to this later.\n",
    "\n",
    "But first, let's return to the problem of computing the posterior predictive distribution. \n",
    "Since our model is simple (and the prior is conjugate to the likelihood), we don't need to resort to sampling. \n",
    "We can evaluate the posterior predictive distribution analytically, to obtain the following solution:\n",
    "\n",
    "$$\n",
    "\\begin{gather}\n",
    "y_{*} | \\xs_*, \\Xs, \\ys, \\sigma^2, \\gamma^2 \\sim \\operatorname{Normal}\\!\\left[\\xs_{*}^\\top \\ws_N, \\sigma^2_N(\\xs_{*})\\right] \\\\\n",
    "\\text{where} \\quad \\sigma^2_N(\\xs_{*}) = \\sigma^2 + \\xs_{*}^\\top \\Vs_N \\xs_{*}\n",
    "\\end{gather}\n",
    "$$\n",
    "\n",
    "Note that the predictive mean is a simple application of the posterior mean to the data point, but the predictive variance is a bit more complicated. \n",
    "\n",
    "***\n",
    "**Exercise:** Complete the functions below to evaluate the predictive mean $\\xs_{*}^\\top \\ws_N$ and predictive standard deviation $\\sigma_N(\\mathbf{x}_{*})$ for a collection of test instances. \n",
    "Then run the following code block to plot the results.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictive_mean(X, w):\n",
    "    \"\"\"\n",
    "    Compute the predictive mean for the response, given X and w\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X : numpy array, shape (n_instances, n_features)\n",
    "        feature matrix\n",
    "    w : numpy array, shape (n_features,)\n",
    "        weights vector\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    Y_mean : numpy array, shape: (n_instances,)\n",
    "        predictive mean for each instance in X\n",
    "    \"\"\"\n",
    "    # your code here #\n",
    "    pass\n",
    "\n",
    "def predictive_std(X, V_N, sigma):\n",
    "    \"\"\"\n",
    "    Compute the predictive standard deviation for the response, given X, V_N and sigma\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X : numpy array, shape (n_instances, n_features)\n",
    "        feature matrix\n",
    "    V_N : numpy array, shape: (n_features, n_features)\n",
    "        covariance parameter\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    std : numpy array, shape (n_instances,)\n",
    "        predictive standard deviation for each instance in X\n",
    "    \"\"\"\n",
    "    # your code here #\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test_mean = predictive_mean(Phi_test, w_N)\n",
    "Y_test_std = predictive_std(Phi_test, V_N, sigma)\n",
    "\n",
    "plt.plot(X, Y, 'ro', label='Train')\n",
    "plt.fill_between(X_test.ravel(), Y_test_mean + 2*Y_test_std, Y_test_mean - 2*Y_test_std, \n",
    "                 alpha=0.1, label='95% CI')\n",
    "plt.plot(X_test.ravel(), Y_test_mean, 'g:', label='Predictive mean')\n",
    "plt.plot(X_test.ravel(), Y_test_gold, 'k', label='Model mean')\n",
    "\n",
    "plt.ylim(-2, 5)\n",
    "plt.xlabel('$x$')\n",
    "plt.ylabel('$y$')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "**Discussion questions**: \n",
    "\n",
    "1. How does the exact plot of predictive uncertainty compare to the sample-based one? How does the uncertainty change relative to the distance from training points? Can you explain why?\n",
    "\n",
    "2. Is a 9th degree polynomial a good choice for this problem? Based on the results above, would you recommend this model, or make a different choice?\n",
    "\n",
    "3. How does the setting of `gamma` affect the fit? How about the number of instances in the training set? Try some other values and see what happens.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Bayesian model selection\n",
    "In this section, we'll revisit the assumption of using 9th degree polynomial features. \n",
    "To do this, we'll evaluate competing models using the _model evidence_.\n",
    "When applied to our regression model, the model evidence can be expressed as follows:\n",
    "\n",
    "$$\n",
    "p(\\ys|\\Xs, \\sigma, \\gamma) = \\int p(\\ys | \\Xs, \\sigma, \\gamma, \\ws) p(\\ws) \\, \\mathrm{d} \\ws.\n",
    "$$\n",
    "\n",
    "In words, we compute the likelihood conditioned on the model, and marginalise out the model parameters with respect to their prior distributions (see Sec 3.4 of Bishop).\n",
    "\n",
    "Since our model is relatively simple, we can evaluate the evidence in closed form. \n",
    "We have\n",
    "\n",
    "$$\n",
    "\\log p(\\ys|\\Xs, \\sigma, \\gamma) = - (d+1) \\log \\gamma - n \\log \\sigma - E(\\ws_N) - \\frac{1}{2} \\log |\\Vs_N^{-1}| - \\frac{n}{2} \\log 2\\pi\n",
    "$$\n",
    "\n",
    "where $E(\\ws_N) = \\frac{1}{2 \\sigma^2} \\|\\ys - \\Xs \\ws_N \\|_2^2 + \\frac{1}{2 \\gamma^2} |\\ws_N|_2^2$.\n",
    "\n",
    "In the code block below we implement a function that computes the log-evidence for a given posterior mean $\\ws_N$, training data $\\Xs$, $\\ys$ and variance parameters $\\sigma$ and $\\gamma$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_evidence(w_N, X, Y, sigma, gamma):\n",
    "    n_instances, n_features = X.shape\n",
    "    alpha, beta = 1/gamma**2, 1/sigma**2\n",
    "    rss = np.sum((Y - np.dot(X, w_N))**2)\n",
    "    wpen = np.dot(w_N, w_N)\n",
    "    E = beta/2 * rss + alpha/2 * wpen\n",
    "    A = alpha * np.identity(n_features) + beta * X.T @ X\n",
    "    lE = n_features/2 * np.log(alpha) + n_instances/2 * np.log(beta) - E \\\n",
    "        - 0.5 * np.log(np.linalg.det(A)) - n_instances/2 * np.log(2 * np.pi)\n",
    "    # return both the evidence, and the RSS term (the raw quality of fit)\n",
    "    return {'logEvidence': lE, 'RSS': rss}\n",
    "\n",
    "# what's the evidence for our 9th degree model?\n",
    "compute_evidence(w_N, Phi, Y, sigma, gamma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So what happens if we use lower degree polynomial features, e.g., 3rd degree polynomial features?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Phi_3, Phi_3_test = polynomial_features(X, X_test, 3)\n",
    "\n",
    "w_N_3, V_N_3 = compute_posterior_params(Phi_3, Y, sigma, gamma)\n",
    "Y_test = predictive_mean(Phi_3_test, w_N_3)\n",
    "Y_test_std = predictive_std(Phi_3_test, V_N_3, sigma)\n",
    "\n",
    "plt.plot(X, Y, 'ro', label='Train')\n",
    "plt.fill_between(X_test.ravel(), Y_test_mean + 2*Y_test_std, Y_test_mean - 2*Y_test_std, alpha=0.1, label='95% CI')\n",
    "plt.plot(X_test.ravel(), Y_test_mean, 'g:', label='Predictive mean')\n",
    "plt.plot(X_test.ravel(), Y_test_gold, 'k', label='Model mean')\n",
    "\n",
    "plt.ylim(-2,5)\n",
    "plt.xlabel('$x$')\n",
    "plt.ylabel('$y$')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "**Discussion**: Does that look like a better fit to you? Consider both the interval $[0,1]$ near the training points, and those outside this range.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what the *evidence* says, and compare this to the above result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_evidence(w_N_3, Phi_3, Y, sigma, gamma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The RSS has barely changed, but the evidence is much higher. We can look at various polynomial degrees to see which has the best *evidence* to perform Bayesian model selection: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_range = np.arange(1, 11)\n",
    "logEvidence = []\n",
    "RSS = []\n",
    "for k in k_range:\n",
    "    Phi_k, Phi_k_test = polynomial_features(X, X_test, k)\n",
    "    w_N_k, V_N_k = compute_posterior_params(Phi_k, Y, sigma, gamma)\n",
    "    result = compute_evidence(w_N_k, Phi_k, Y, sigma, gamma)\n",
    "    print('Degree {}. Log evidence {}. RSS {}.'.format(k, result['logEvidence'], result['RSS']))\n",
    "    logEvidence.append(result['logEvidence'])\n",
    "    RSS.append(result['RSS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the above log evidence values against the polynomial degree\n",
    "ax1 = plt.subplot(211)\n",
    "ax1.plot(k_range, logEvidence)\n",
    "plt.setp(ax1.get_xticklabels(), visible=False)\n",
    "plt.ylabel('Log Evidence')\n",
    "\n",
    "ax2 = plt.subplot(212, sharex=ax1)\n",
    "ax2.plot(k_range, RSS)\n",
    "plt.xlabel('Polynomial degree')\n",
    "plt.ylabel('RSS')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "**Discussion**: So which model class will be chosen? Is this a reasonable situation? \n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus: Bayesian regression with unknown variance (optional)\n",
    "\n",
    "In real settings, the variance for $y$, $\\sigma^2$ is unknown.\n",
    "It's possible to account for this by putting the following prior on $\\sigma^{2}$:\n",
    "$$\n",
    "\\sigma^{-2} \\sim \\textrm{Gamma}(\\alpha_1, \\alpha_2)\n",
    "$$\n",
    "where $\\alpha_1, \\alpha_2 > 0$ are hyperparameters.\n",
    "\n",
    "We can also put a prior over the variance for the weights, $\\gamma^2$:\n",
    "$$\n",
    "\\gamma^{-2} \\sim \\textrm{Gamma}(\\lambda_1, \\lambda_2)\n",
    "$$\n",
    "where $\\lambda_1, \\lambda_2 > 0$ are hyperparameters.\n",
    "\n",
    "This model for regression (with the additional priors over $\\gamma$ and $\\sigma$) is implemented in `sklearn.linear_models.BayesianRidge`.\n",
    "\n",
    "***\n",
    "**Exercise**: Apply `BayesianRidge` to the training data (with the polynomial basis expansion) and compare the results to our simpler model.\n",
    "What happens if the value of $\\sigma$ used in our model deviates from the true value used to generate the data?\n",
    "Is `BayesianRidge` more robust in this case?\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = BayesianRidge(compute_score=True, fit_intercept=False).fit(Phi, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test_mean, Y_test_std = reg.predict(Phi_test, return_std=True)\n",
    "\n",
    "plt.plot(X, Y, 'ro', label='Train')\n",
    "plt.fill_between(X_test.ravel(), Y_test_mean + 2*Y_test_std, Y_test_mean - 2*Y_test_std, alpha=0.1, label='95% CI')\n",
    "plt.plot(X_test, Y_test_mean, 'g:', label='Predictive mean')\n",
    "plt.plot(X_test, Y_test_gold, 'k', label='Model mean')\n",
    "\n",
    "plt.ylim(-2,5)\n",
    "plt.xlabel('$x$')\n",
    "plt.ylabel('$y$')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
